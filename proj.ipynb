{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import transforms, datasets\n",
    "\n",
    "datasets.FashionMNIST(\"data\", train=True, download=True)\n",
    "datasets.FashionMNIST(\"data\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torchvision\n",
    "import torchvision.models.resnet\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from pytorch_lightning import Trainer\n",
    "# %pip install wandb\n",
    "import wandb\n",
    "\n",
    "# %pip install lightning\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, dropout=0.25):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(dropout) if dropout else nn.Identity(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(dropout) if dropout else nn.Identity(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout) if dropout else nn.Identity(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            m.bias.data.fill_(0.00)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "            m.bias.data.fill_(0.00)\n",
    "        # if fc2 is the last layer, we can use the following initialization\n",
    "        if m == self.layers[-1]:\n",
    "            init.xavier_uniform_(m.weight, gain=init.calculate_gain('linear'))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTData(L.LightningDataModule):\n",
    "    def __init__(self, batch_size=64):\n",
    "        super().__init__()\n",
    "        self.train_set = None\n",
    "        self.val_set = None\n",
    "        self.test_set = None\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        train_set = datasets.FashionMNIST(\"data\", train=True, download=True,\n",
    "                                          transform=transforms.Compose([transforms.ToTensor()]))\n",
    "        self.test_set = datasets.FashionMNIST(\"data\", train=False, download=True,\n",
    "                                              transform=transforms.Compose([transforms.ToTensor()]))\n",
    "        self.train_set, self.val_set = torch.utils.data.random_split(train_set, [50000, 10000])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True, num_workers=15, persistent_workers=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=self.batch_size, num_workers=15, persistent_workers=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, batch_size=self.batch_size, num_workers=15, persistent_workers=True)\n",
    "\n",
    "\n",
    "class Classifier(L.LightningModule):\n",
    "    def __init__(self, model=None, lr=0.001, dropout=0.25, weight_decay=1e-5):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.model = model if model is not None else ConvNet(dropout)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "        accuracy = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log_dict({\"val/loss\": loss, \"val/accuracy\": accuracy})\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "        accuracy = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log_dict({\"test/loss\": loss, \"test/accuracy\": accuracy})\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mziele14\u001b[0m (\u001b[33mziele14-poznan-univeristy-of-technology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20241125_134601-yugcz24l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ziele14-poznan-univeristy-of-technology/fashion_mnist_project/runs/yugcz24l' target=\"_blank\">soft-mountain-5</a></strong> to <a href='https://wandb.ai/ziele14-poznan-univeristy-of-technology/fashion_mnist_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ziele14-poznan-univeristy-of-technology/fashion_mnist_project' target=\"_blank\">https://wandb.ai/ziele14-poznan-univeristy-of-technology/fashion_mnist_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ziele14-poznan-univeristy-of-technology/fashion_mnist_project/runs/yugcz24l' target=\"_blank\">https://wandb.ai/ziele14-poznan-univeristy-of-technology/fashion_mnist_project/runs/yugcz24l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type    | Params | Mode \n",
      "------------------------------------------\n",
      "0 | model | ConvNet | 421 K  | train\n",
      "------------------------------------------\n",
      "421 K     Trainable params\n",
      "0         Non-trainable params\n",
      "421 K     Total params\n",
      "1.687     Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 782/782 [00:05<00:00, 130.72it/s, v_num=z24l]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 782/782 [00:06<00:00, 130.22it/s, v_num=z24l]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:01<00:00, 105.57it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test/accuracy          0.911899983882904\n",
      "        test/loss           0.24953396618366241\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Test Results: [{'test/loss': 0.24953396618366241, 'test/accuracy': 0.911899983882904}]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "data_module = MNISTData()\n",
    "convnet_classifier = Classifier(lr=0.001, dropout=0.25)\n",
    "\n",
    "wandb_logger = WandbLogger(project=\"fashion_mnist_project\")\n",
    "\n",
    "\n",
    "trainer = L.Trainer(max_epochs=10, accelerator='gpu', devices=1, logger=wandb_logger)\n",
    "\n",
    "\n",
    "trainer.fit(convnet_classifier, data_module)\n",
    "metrics = trainer.logged_metrics[\"val/accuracy\"]\n",
    "test_results = trainer.test(convnet_classifier, datamodule=data_module)\n",
    "print(\"Test Results:\", test_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(convnet_classifier.state_dict(), \"convnet_classifier.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantized dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model_dynamic = Classifier(lr=0.001, dropout=0.25)\n",
    "quantized_model_dynamic.load_state_dict(torch.load(\"convnet_classifier.pth\"))\n",
    "quantized_model_dynamic.model = torch.quantization.quantize_dynamic(\n",
    "    quantized_model_dynamic.model,  \n",
    "    {torch.nn.Linear}, \n",
    "    dtype=torch.qint8  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model = Classifier(lr=0.001, dropout=0.25)\n",
    "pruned_model.load_state_dict(torch.load(\"convnet_classifier.pth\"))\n",
    "parameters_to_prune = (\n",
    "    (pruned_model.model.layers[0], 'weight'),\n",
    "    (pruned_model.model.layers[4], 'weight'),\n",
    "    (pruned_model.model.layers[9], 'weight'),\n",
    ")\n",
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=0.2,\n",
    ")\n",
    "\n",
    "for module, param in parameters_to_prune:\n",
    "    prune.remove(module, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_inference_time(model, dataloader, num_warmup=5):\n",
    "    model.eval()\n",
    "    \n",
    "    # warm ups at the start so that the measurements are not skewed\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_warmup):\n",
    "            for x, y in dataloader:\n",
    "                model(x)\n",
    "    \n",
    "    start_time = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            model(x)\n",
    "    end_time = time.perf_counter()\n",
    "    \n",
    "    return (end_time - start_time) / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size_of_model(model, label=\"\"):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    size=os.path.getsize(\"temp.p\")\n",
    "    print(\"model: \",label,' \\t','Size (KB):', size/1e3)\n",
    "    os.remove('temp.p')\n",
    "    return size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  original  \t Size (KB): 1689.628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1689628"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_size_of_model(convnet_classifier, \"original\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421642"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parameters(convnet_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  quantized  \t Size (KB): 482.946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "482946"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_size_of_model(quantized_model_dynamic, \"quantized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18816"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parameters(quantized_model_dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  pruned  \t Size (KB): 1689.628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1689628"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_size_of_model(pruned_model, \"pruned\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421642"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parameters(pruned_model) #because the weights are zeroed not removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader):\n",
    "    model.eval()  \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader:\n",
    "            outputs = model(x)\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "\n",
    "            all_preds.append(preds.cpu().numpy())  \n",
    "            all_labels.append(y.cpu().numpy())    \n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')  \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    return {\"f1\":f1, \"accuracy\":accuracy, \"precision\":precision, \"recall\":recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1,ac,pr,rc = evaluate(convnet_classifier, data_module.test_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_times ={}\n",
    "inference_times[\"baseline\"] = measure_inference_time(convnet_classifier, data_module.test_dataloader())\n",
    "inference_times[\"quantized_dynamic\"] = measure_inference_time(quantized_model_dynamic, data_module.test_dataloader())\n",
    "inference_times[\"pruned\"] = measure_inference_time(pruned_model, data_module.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_metrics = {}\n",
    "evaluation_metrics[\"baseline\"] = evaluate(convnet_classifier, data_module.test_dataloader())\n",
    "evaluation_metrics[\"quantized_dynamic\"] = evaluate(quantized_model_dynamic, data_module.test_dataloader())\n",
    "evaluation_metrics[\"pruned\"] = evaluate(pruned_model, data_module.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline': {'f1': np.float64(0.9110210839126303),\n",
       "  'accuracy': 0.9119,\n",
       "  'precision': np.float64(0.9131507923675721),\n",
       "  'recall': np.float64(0.9119)},\n",
       " 'quantized_dynamic': {'f1': np.float64(0.9119113933269416),\n",
       "  'accuracy': 0.9128,\n",
       "  'precision': np.float64(0.9139543236372445),\n",
       "  'recall': np.float64(0.9128)},\n",
       " 'pruned': {'f1': np.float64(0.9111225528617409),\n",
       "  'accuracy': 0.912,\n",
       "  'precision': np.float64(0.9132195084547012),\n",
       "  'recall': np.float64(0.912)}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline': 0.012010881528599414,\n",
       " 'quantized_dynamic': 0.01177263503173473,\n",
       " 'pruned': 0.01190352292989446}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>Inference Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.911021</td>\n",
       "      <td>0.9119</td>\n",
       "      <td>0.913151</td>\n",
       "      <td>0.9119</td>\n",
       "      <td>0.012011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quantized_dynamic</td>\n",
       "      <td>0.911911</td>\n",
       "      <td>0.9128</td>\n",
       "      <td>0.913954</td>\n",
       "      <td>0.9128</td>\n",
       "      <td>0.011773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pruned</td>\n",
       "      <td>0.911123</td>\n",
       "      <td>0.9120</td>\n",
       "      <td>0.913220</td>\n",
       "      <td>0.9120</td>\n",
       "      <td>0.011904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model        f1  accuracy  precision  recall  Inference Time\n",
       "0           baseline  0.911021    0.9119   0.913151  0.9119        0.012011\n",
       "1  quantized_dynamic  0.911911    0.9128   0.913954  0.9128        0.011773\n",
       "2             pruned  0.911123    0.9120   0.913220  0.9120        0.011904"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "metrics_df = pd.DataFrame(evaluation_metrics).T.reset_index().rename(columns={'index': 'Model'})\n",
    "times_df = pd.DataFrame(inference_times, index=[0]).T.reset_index().rename(columns={'index': 'Model', 0: 'Inference Time'})\n",
    "\n",
    "result_df = pd.merge(metrics_df, times_df, on='Model')\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightConvNet(nn.Module):\n",
    "    def __init__(self, dropout=0.25):\n",
    "        super(LightConvNet, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(dropout) if dropout else nn.Identity(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(8, 16, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(dropout) if dropout else nn.Identity(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16 * 7 * 7, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout) if dropout else nn.Identity(),\n",
    "            nn.Linear(32, 10)\n",
    "        )\n",
    "\n",
    "        self.apply(self.init_weights)\n",
    "        \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "student_model_one = Classifier(model=LightConvNet(), lr=0.001, dropout=0.25)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "second_student_model = Classifier(model=LightConvNet(), lr=0.001, dropout=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26698"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parameters(student_model_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26698"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parameters(second_student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:654: Checkpoint directory .\\fashion_mnist_project\\yugcz24l\\checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type         | Params | Mode \n",
      "-----------------------------------------------\n",
      "0 | model | LightConvNet | 26.7 K | train\n",
      "-----------------------------------------------\n",
      "26.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "26.7 K    Total params\n",
      "0.107     Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 782/782 [00:06<00:00, 117.68it/s, v_num=z24l]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 782/782 [00:06<00:00, 117.46it/s, v_num=z24l]\n"
     ]
    }
   ],
   "source": [
    "# wandb_logger = WandbLogger(project=\"fashion_mnist_project\")\n",
    "trainer = L.Trainer(max_epochs=10, accelerator='gpu', devices=1, logger=wandb_logger)\n",
    "trainer.fit(student_model_one, data_module)\n",
    "metrics = trainer.logged_metrics[\"val/accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:01<00:00, 97.15it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test/accuracy         0.8840000033378601\n",
      "        test/loss           0.3209458589553833\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Test Results: [{'test/loss': 0.3209458589553833, 'test/accuracy': 0.8840000033378601}]\n",
      "Test Results trainer: [{'test/loss': 0.24953396618366241, 'test/accuracy': 0.911899983882904}]\n"
     ]
    }
   ],
   "source": [
    "test_results_light = trainer.test(student_model_one, datamodule=data_module)\n",
    "print(\"Test Results:\", test_results_light)\n",
    "print(\"Test Results trainer:\", test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student_model_one.state_dict(), \"student.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier_distillation(L.LightningModule):\n",
    "    def __init__(self, model=None, teacher=None, lr=0.001, dropout=0.25, weight_decay=1e-5, T=2, soft_target_loss_weight=0.25, ce_loss_weight=0.75):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.model = model if model is not None else ConvNet(dropout)\n",
    "        self.teacher = teacher\n",
    "        self.T = T\n",
    "        self.soft_target_loss_weight = soft_target_loss_weight\n",
    "        self.ce_loss_weight = ce_loss_weight\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        student_logits = self(x)\n",
    "        label_loss = self.ce_loss(student_logits, y)\n",
    "\n",
    "        if self.teacher:\n",
    "            with torch.no_grad():\n",
    "                teacher_logits = self.teacher(x)\n",
    "            soft_targets = nn.functional.softmax(teacher_logits / self.T, dim=-1)\n",
    "            soft_prob = nn.functional.log_softmax(student_logits / self.T, dim=-1)\n",
    "            soft_targets_loss = torch.sum(soft_targets * (soft_targets.log() - soft_prob)) / soft_prob.size()[0] * (self.T**2)\n",
    "            loss = self.soft_target_loss_weight * soft_targets_loss + self.ce_loss_weight * label_loss\n",
    "        else:\n",
    "            loss = label_loss\n",
    "\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "        accuracy = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        self.log(\"val/accuracy\", accuracy, prog_bar=True)\n",
    "        return {\"val_loss\": loss, \"val_accuracy\": accuracy}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "        accuracy = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log_dict({\"test/loss\": loss, \"test/accuracy\": accuracy})\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# student_model_one.load_state_dict(torch.load(\"student.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'teacher' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['teacher'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:654: Checkpoint directory .\\fashion_mnist_project\\yugcz24l\\checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | Classifier       | 26.7 K | eval \n",
      "1 | teacher | Classifier       | 421 K  | eval \n",
      "2 | ce_loss | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "448 K     Trainable params\n",
      "0         Non-trainable params\n",
      "448 K     Total params\n",
      "1.793     Total estimated model params size (MB)\n",
      "1         Modules in train mode\n",
      "32        Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 782/782 [00:08<00:00, 97.10it/s, v_num=z24l, val/loss=0.229, val/accuracy=0.916] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 782/782 [00:08<00:00, 96.87it/s, v_num=z24l, val/loss=0.229, val/accuracy=0.916]\n"
     ]
    }
   ],
   "source": [
    "teacher_model = convnet_classifier\n",
    "student_model = second_student_model\n",
    "classifier = Classifier_distillation(model=student_model, teacher=teacher_model)\n",
    "\n",
    "# wandb_logger = WandbLogger(project=\"fashion_mnist_project\")\n",
    "trainer = L.Trainer(max_epochs=10, accelerator='gpu', devices=1, logger=wandb_logger)\n",
    "\n",
    "trainer.fit(classifier, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:01<00:00, 99.76it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test/accuracy         0.8996999859809875\n",
      "        test/loss           0.2757464349269867\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Test Results: [{'test/loss': 0.2757464349269867, 'test/accuracy': 0.8996999859809875}]\n"
     ]
    }
   ],
   "source": [
    "test_results_distilled = trainer.test(classifier, datamodule=data_module)\n",
    "print(\"Test Results:\", test_results_distilled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(classifier.state_dict(), \"student_distilled.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:01<00:00, 103.15it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test/accuracy         0.8996999859809875\n",
      "        test/loss           0.2757464349269867\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "convnet_metrics = test_results\n",
    "convnet_inference_time = measure_inference_time(convnet_classifier, data_module.test_dataloader())\n",
    "\n",
    "student_1_metrics = test_results_light\n",
    "student_1_inference_time = measure_inference_time(student_model_one, data_module.test_dataloader())\n",
    "\n",
    "student_2_metrics = trainer.test(classifier, datamodule=data_module)\n",
    "student_2_inference_time = measure_inference_time(classifier, data_module.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_metrics = {}\n",
    "evaluation_metrics[\"baseline\"] = evaluate(convnet_classifier, data_module.test_dataloader())\n",
    "evaluation_metrics[\"student_one\"] = evaluate(student_model_one, data_module.test_dataloader())\n",
    "evaluation_metrics[\"student_two\"] = evaluate(classifier, data_module.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Inference Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ConvNet baseline</td>\n",
       "      <td>0.9119</td>\n",
       "      <td>0.249534</td>\n",
       "      <td>0.913151</td>\n",
       "      <td>0.9119</td>\n",
       "      <td>0.911021</td>\n",
       "      <td>0.012287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Student Model 1</td>\n",
       "      <td>0.8840</td>\n",
       "      <td>0.320946</td>\n",
       "      <td>0.883589</td>\n",
       "      <td>0.8840</td>\n",
       "      <td>0.883581</td>\n",
       "      <td>0.007893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Student Model 2</td>\n",
       "      <td>0.8997</td>\n",
       "      <td>0.275746</td>\n",
       "      <td>0.899897</td>\n",
       "      <td>0.8997</td>\n",
       "      <td>0.899260</td>\n",
       "      <td>0.008605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model  Accuracy      Loss  Precision  Recall  F1 Score  \\\n",
       "0  ConvNet baseline    0.9119  0.249534   0.913151  0.9119  0.911021   \n",
       "1   Student Model 1    0.8840  0.320946   0.883589  0.8840  0.883581   \n",
       "2   Student Model 2    0.8997  0.275746   0.899897  0.8997  0.899260   \n",
       "\n",
       "   Inference Time (s)  \n",
       "0            0.012287  \n",
       "1            0.007893  \n",
       "2            0.008605  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {\n",
    "    'Model': ['ConvNet baseline', 'Student Model 1', 'Student Model 2'],\n",
    "    'Accuracy': [convnet_metrics[0]['test/accuracy'], student_1_metrics[0]['test/accuracy'], student_2_metrics[0]['test/accuracy']],\n",
    "    'Loss': [convnet_metrics[0]['test/loss'], student_1_metrics[0]['test/loss'], student_2_metrics[0]['test/loss']],\n",
    "    'Precision': [\n",
    "        evaluation_metrics[\"baseline\"][\"precision\"],\n",
    "        evaluation_metrics[\"student_one\"][\"precision\"],\n",
    "        evaluation_metrics[\"student_two\"][\"precision\"]\n",
    "    ],\n",
    "    'Recall': [\n",
    "        evaluation_metrics[\"baseline\"][\"recall\"],\n",
    "        evaluation_metrics[\"student_one\"][\"recall\"],\n",
    "        evaluation_metrics[\"student_two\"][\"recall\"]\n",
    "    ],\n",
    "    'F1 Score': [\n",
    "        evaluation_metrics[\"baseline\"][\"f1\"],\n",
    "        evaluation_metrics[\"student_one\"][\"f1\"],\n",
    "        evaluation_metrics[\"student_two\"][\"f1\"]\n",
    "    ],\n",
    "    'Inference Time (s)': [convnet_inference_time, student_1_inference_time, student_2_inference_time]\n",
    "}\n",
    "\n",
    "results_df_two = pd.DataFrame(results)\n",
    "\n",
    "results_df_two"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
