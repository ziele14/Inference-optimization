# Inference-optimization
Results of the third project created for MLOps course regarding inference optimization.

The repository consists of one Jupyter notebook with code implementing model quantization, weights pruning, and knowledge distillation for a model used in the previous lab and three files storing pre-trained weights for baseline, student, and distilled student models created during training.
